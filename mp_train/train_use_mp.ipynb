{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.2 (SDL 2.28.3, Python 3.9.18)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import sys\n",
    "sys.path.append(\"C:/Users/weiso131/Desktop/gameAI/squid/squid_AI_train/\")\n",
    "\n",
    "from Q_learning_train_mp import QLearningTraining\n",
    "from squid_env import trainSquid\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    # 創建環境和 Q-learning 代理\n",
    "    \n",
    "\n",
    "    episodes = 100\n",
    "\n",
    "    # 初始化訓練類\n",
    "    q_learning_trainer = QLearningTraining(\n",
    "        obsShape=(4, 4, 4, 4, 10, 10, 10),\n",
    "        actionSpace=[\"LEFT\",\"RIGHT\", \"DOWN\", \"UP\"],\n",
    "        env=trainSquid, \n",
    "        episodes=episodes, \n",
    "        threadNum=30, \n",
    "        gamma=0.99\n",
    "    )\n",
    "\n",
    "    q_learning_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygame\n",
    "from Q_learing_mp import step\n",
    "def opponent(obs):\n",
    "    actionSpace = [\"LEFT\",\"RIGHT\", \"UP\", \"DOWN\"]\n",
    "    foodScore = obs\n",
    "    return actionSpace[np.argmin(foodScore)]\n",
    "\n",
    "\n",
    "def show():\n",
    "    newEnv = q_learning_trainer.env(level=8)\n",
    "    state, reward, terminated, truncated, _ = newEnv.reset()\n",
    "    while True:\n",
    "        newEnv.render()\n",
    "        action1 = step(q_learning_trainer.shm.name, q_learning_trainer.Qshape, \n",
    "                       q_learning_trainer.Qdtype, q_learning_trainer.actionSpace, \n",
    "                       state[0], 0)\n",
    "        commands = {\"1P\" : [action1],  \n",
    "                    \"2P\" : [opponent(tuple(state[1]))]}\n",
    "        \n",
    "\n",
    "        next_state, reward, terminated, truncated, _ = \\\n",
    "            newEnv.step(commands)\n",
    "        \n",
    "\n",
    "        state = next_state#感你娘機掰\n",
    "        \n",
    "        \n",
    "        if (terminated):\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "show()\n",
    "pygame.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"4wayPotential.pickle\", \"wb\") as f:\n",
    "    pickle.dump(q_learning_trainer.agent.Q_form, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_learning_trainer.agent.end_shm()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
